## On Climate, Environment, and GenAI's Potential Impact

Environmental concerns around generative AI have become increasingly visible in public discourse, often framed in urgent or alarming terms. These concerns are not fabricated, but they are also not straightforward. The data on energy and water use associated with AI systems is incomplete, unevenly reported, and difficult to contextualize in ways that support informed decision-making. For language educators working within institutions that have made public commitments to environmental sustainability, these questions can feel both pressing and unresolvable.

### Energy Use and the Challenge of Comparison

Training large language models requires significant computational resources, which translates to substantial energy consumption. The exact figures vary widely depending on model size, training duration, hardware efficiency, and energy sources used by data centers. Estimates are often reported in terms that are technically accurate but hard to interpret: megawatt-hours, carbon dioxide equivalents, or comparisons to the energy use of entire households over months or years.

It is also important to recognize that model training is not a one-time event. While it is sometimes framed as a large upfront cost followed by lower-cost inference, the reality is more complex. Models are continuously updated, retrained on new data, and iteratively improved. New versions are released, fine-tuned variants are created for specific applications, and ongoing research produces additional models. This means that the energy costs of training are not a historical sunk cost but an ongoing environmental burden that accumulates over time.

What makes these numbers difficult to assess is the lack of clear baselines for comparison. Is the energy cost of training a large model comparable to a year of video streaming by millions of users? To the emissions from a single transatlantic flight? To the operational costs of traditional computing infrastructure? These comparisons are rarely apples to apples, and they depend heavily on assumptions about how energy is measured, what gets included in the calculation, and what energy sources are powering the data centers in question.

Inference (the process of generating responses to user prompts) requires less energy than training, but it scales with usage. As generative AI becomes more widespread, the cumulative energy cost of billions of queries adds up. However, contextualizing that cost against other forms of digital activity (video conferencing, social media, cloud storage, online gaming) remains difficult. Some research suggests that a single AI-generated response uses energy comparable to a few web searches or a short video stream, but these figures are contested and vary by model and infrastructure.

What is clearer is that the energy intensity of AI is not static. Efficiency improvements in hardware, optimization of algorithms, and shifts toward renewable energy sources in data centers can reduce the per-query environmental cost over time. But growth in usage can outpace those gains, meaning that even as individual queries become less resource-intensive, the overall environmental footprint may still increase.

For instructors, this complexity creates a real challenge. It is difficult to know whether encouraging or requiring AI use in a course meaningfully contributes to environmental harm, especially when compared to other institutionally supported activities that also carry environmental costs. The data simply does not support confident claims in either direction.

### Water Use and Data Center Cooling

Water consumption has emerged as another focal point of concern, particularly in regions experiencing drought or water scarcity. Data centers generate significant heat and require cooling systems to operate effectively. Some facilities use water-intensive cooling methods, including evaporative cooling towers that consume large volumes of freshwater. Others rely on air cooling or closed-loop systems that use far less water.

The environmental impact of water use depends heavily on local context: the availability of water in the region, the specific cooling technologies employed, and whether water is returned to the local ecosystem or lost to evaporation. Reports have documented cases where data center water use has strained local resources, raised utility costs for nearby residents, or contributed to tensions between municipal governments and corporate operators.

But here again, the data is uneven. Companies do not always report water use transparently, and when they do, the figures are difficult to compare across facilities or against other industrial water users. Agricultural operations, manufacturing plants, and power generation facilities often consume water at far greater scales, but data centers are newer, more visible, and associated with rapidly growing tech industries, which may explain why they attract disproportionate public attention.

For instructors and students, this raises questions about individual versus collective responsibility. A student generating a few dozen AI responses for a language assignment is unlikely to be the determining factor in regional water stress. But if millions of students are doing the same thing, and if institutional adoption of AI tools continues to grow, the cumulative impact becomes harder to dismiss.

### Local Impacts and Community Concerns

Perhaps the most tangible environmental concerns are those that operate at the local level. Data centers are physical infrastructure, and their presence affects the communities around them. They require land, generate noise, consume electricity from local grids, and can strain municipal water and energy resources. In some cases, they have been sited in low-income communities or areas with weaker regulatory oversight, raising environmental justice concerns.

Ann Arbor and the University of Michigan have both made public commitments to carbon neutrality and environmental sustainability. These commitments sit uneasily alongside the growing adoption of AI tools across campus, including in teaching and learning. While the university does not operate the data centers that power commercial AI platforms, its use of those platforms contributes to demand, and therefore indirectly to the environmental costs associated with their operation.

This dynamic is not unique to AI. Universities have long grappled with the environmental trade-offs of digital infrastructure, from energy-intensive research computing to the carbon footprint of cloud storage and video streaming. But generative AI has become a flashpoint, in part because its adoption has been so rapid and so visible, and in part because it is easier to imagine alternatives to AI use than to other forms of digital activity that feel essential.

### Implications for Language Educators

These environmental concerns do not resolve into clear guidance, but they do invite reflection. For instructors thinking about whether and how to incorporate generative AI into their courses, several considerations may be relevant:

- **Alignment with institutional values.** If the university has committed to environmental sustainability, instructors may reasonably ask whether widespread AI adoption is consistent with those commitments, and whether the institution has mechanisms in place to account for the environmental costs of its technology choices.
- **Pedagogical necessity.** Not all uses of AI in teaching carry the same pedagogical value. Assignments that require students to generate dozens of AI responses may be worth reconsidering if the learning outcomes could be achieved through lower-impact alternatives. This does not mean avoiding AI entirely, but it does mean being intentional about when and why it is used.
- **Transparency with students.** If environmental sustainability is a value held by the instructor or the institution, students have a right to know that AI use carries environmental costs, even if those costs are difficult to quantify precisely. This transparency can be part of a broader conversation about the trade-offs involved in technology use and the importance of informed decision-making.
- **Individual versus institutional responsibility.** Instructors and students are not individually responsible for solving the environmental impacts of AI. These are structural problems that require policy responses, corporate accountability, and regulatory oversight. At the same time, individual choices do aggregate, and being mindful of environmental costs is part of what it means to engage thoughtfully with technology.

It is also worth acknowledging that people will arrive at different conclusions about whether generative AI use is justified given its environmental costs. Some will look at the available data and judge AI use to be inherently frivolous, unnecessary, or wasteful in light of climate concerns. Others will weigh the same information and reach a different conclusion without it meaning they care less about the environment or take climate change less seriously. These are questions of values and priorities, not evidence of presence or absence of environmental concern.

Human societies make these kinds of trade-offs constantly. We could point to air travel, meat consumption, fast fashion, recreational streaming, or countless other activities and declare them evidence of individual or institutional hypocrisy if measured against stated environmental commitments. The reality is that most people and institutions navigate competing values imperfectly, making choices that reflect complex judgments about necessity, benefit, feasibility, and consequence.

The goal here is not to prescribe a single correct answer or to sort people into categories of environmental responsibility. It is to encourage informed reflection: to make visible the costs that are often hidden, to invite consideration of trade-offs, and to support decision-making that is deliberate rather than inadvertent. Instructors who choose to use AI in their teaching are not thereby dismissing environmental concerns, and those who choose not to are not necessarily making that choice primarily on environmental grounds. What matters is that the choice is made thoughtfully, with awareness of what is at stake.

In the end, the question is not whether generative AI has environmental impacts (it does), but whether those impacts are justified by the purposes for which it is used. That is a question each instructor will answer differently, depending on their learning goals, their values, and their sense of what kinds of trade-offs are acceptable in their teaching. What matters is that the question is asked, and that the answers are arrived at thoughtfully rather than by default.