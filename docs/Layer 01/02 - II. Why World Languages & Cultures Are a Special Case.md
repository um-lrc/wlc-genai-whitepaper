Generative AI has touched nearly every discipline in higher education, but it hasn’t done so evenly. In World Languages & Cultures, the changes feel especially close to the core of what we do, not because language instructors are wary of technology, but because language learning works differently from many other kinds of academic learning.

Learning a language is not mainly about producing correct sentences. It’s about building internal capacities: understanding meaning in real time, choosing words under pressure, noticing when communication breaks down, and finding ways to repair it. These abilities develop slowly, through use, feedback, and reflection. They don’t arrive all at once, and they don’t always show up cleanly in a single assignment.

At the same time, instructors work within real institutional constraints. Courses require grades. Programs require evidence. Universities need visible markers of progress. Written work, oral performances, and other concrete products are the shared language higher education uses to talk about learning. Relying on these artifacts isn't a mistake; it's a practical necessity.

Generative AI changes the terms of that arrangement. When polished language can be produced quickly and externally, it becomes harder to know what a finished product actually represents. The issue isn’t that assessment is suddenly wrong, but that the link between what we see and what students are learning becomes less clear.

This is where the difference between _knowing that_ and _knowing how_ matters. A student may recognize a grammatical form or explain a rule long before they can use it naturally in conversation or writing. Language learning depends on timing, hesitation, choice, and interaction. It shows up in how students respond in the moment, not just in what they can describe after the fact.

Language learning is also deeply tied to culture and identity. To learn a language is to learn how meaning works in different settings, with different people, and under different social expectations. Students experiment with tone and voice as they build an L2 self. That process is often tentative and imperfect, and that imperfection is part of the learning.

Seen this way, the question isn't whether generative AI can produce language (it clearly can). The more useful question is whether its use in a particular activity helps students develop the capacities that language courses are meant to support. In some cases, AI tools may be useful for analysis or reflection. In others, they may get in the way of the very processes instructors are trying to encourage.

Recognizing World Languages & Cultures as a special case doesn't mean rejecting AI or ignoring institutional realities. It means being clearer about what different kinds of assignments are meant to do, what they can reasonably show, and where instructor judgment still matters. The aim is to support thoughtful, discipline-specific choices rather than one-size-fits-all solutions.

---
### Bibliography

Ellis, N. C. (2004). The processes of second language acquisition. In B. VanPatten & J. Williams (Eds.), Theories in second language acquisition: An introduction (pp. 66-82). Lawrence Erlbaum Associates.

Kim, L. S. (2003). Exploring the relationship between language, culture and identity. GEMA Online Journal of Language Studies, 3(2).

Salaberry, M. R. (2018). Declarative versus procedural knowledge. The TESOL Encyclopedia of English language teaching, 1-7.