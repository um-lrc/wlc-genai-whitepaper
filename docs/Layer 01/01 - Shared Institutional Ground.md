# Shared Institutional Ground

Several points of common ground have already emerged across the university. Over the past several years, faculty, staff, and administrators have spent considerable time grappling with what generative AI means for teaching and learning. While perspectives and practices continue to evolve, several broad understandings are now widely shared.

First, generative AI is part of the academic landscape. It is not a hypothetical future development, nor something that can be meaningfully addressed through avoidance alone. Students encounter these tools in many contexts, both inside and outside the university, and they will continue to do so. The question is no longer whether AI exists, but how instructors and programs respond to its presence in ways that support learning.

Second, experience has shown that detection- and surveillance-based approaches offer limited benefits and carry real costs. AI detection tools are unreliable, uneven across disciplines and languages, and prone to false positives. In many cases, they create more confusion and anxiety than clarity. For this reason, there is growing recognition that teaching and assessment strategies grounded in trust, transparency, and instructional design are more effective than those centered on monitoring and enforcement.

Third, faculty retain professional discretion in shaping their courses. There is no single required stance toward generative AI, and no expectation that all instructors adopt the same practices. Decisions about whether and how AI fits into a course properly belong with instructors, informed by their learning goals, student populations, and disciplinary norms.

Finally, equity, access, and transparency are central concerns. AI tools can function as supports for some students and barriers for others. At the same time, blanket prohibitions or opaque policies can unintentionally disadvantage multilingual students, students with disabilities, or those navigating unequal access to resources. Thoughtful responses to generative AI must take these complexities seriously.

Just as important is what this document does _not_ attempt to do. It does not provide a general introduction to generative AI or evaluate specific tools. It does not prescribe a single policy or position that faculty are expected to adopt. And it does not frame AI use primarily as an academic integrity problem to be solved through control.

Instead, this primer starts from the recognition that instructors are already navigating these issues with care and professionalism. Its purpose is to support that work by offering a shared framework for thinking about learning, assessment, and instructional design in World Languages & Cultures, now that the initial disruption has passed and more deliberate choices are possible.

--- 
### Bibliography

Ardito, C. G. (2025). Generative AI detection in higher education assessments. New Directions for Teaching and Learning, 2025(1), 1-15. https://onlinelibrary.wiley.com/doi/abs/10.1002/tl.20624

Parker, G. (2025). Unforgetting Educational Surveillance: Reimagining AI as a Tool for Justice and Pedagogical Liberation. Big Data Analytics & Applications, 27.